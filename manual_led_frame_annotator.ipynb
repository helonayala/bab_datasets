{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manual LED Onset Annotation\n",
        "\n",
        "Use this notebook to scrub frames and record the LED-on frame index for each video.\n",
        "This is independent of `bab_datasets` syncing code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Video path and limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your local video path\n",
        "\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/swept_sine.MOV\",\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/rampa_positiva.MOV\"\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/rampa_negativa.MOV\"\n",
        "# video_path =  \"/Users/helon/Desktop/neural_ODE/videos_BAB/random_steps_W.MOV\"\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/random_steps_X.MOV\"\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/random_steps_Y.MOV\"\n",
        "# video_path =  \"/Users/helon/Desktop/neural_ODE/videos_BAB/random_steps_Z.MOV\"\n",
        "# video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/multisine_01.MOV\"\n",
        "video_path = \"/Users/helon/Desktop/neural_ODE/videos_BAB/multisine_02.MOV\"\n",
        "\n",
        "assert os.path.exists(video_path), video_path\n",
        "\n",
        "# Limit to first N seconds for faster browsing (set None for full video)\n",
        "max_seconds = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fps: 30.001847404396823 frames: 2436 size: (1920, 1080)\n",
            "max_frames: 270\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "cap.release()\n",
        "\n",
        "max_frames = int(fps * max_seconds) if max_seconds is not None else frame_count\n",
        "max_frames = min(max_frames, frame_count)\n",
        "\n",
        "print('fps:', fps, 'frames:', frame_count, 'size:', (width, height))\n",
        "print('max_frames:', max_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Frame browser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c44dd79e3dcb457796f8fc0ee162100e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='frame', max=269), Output()), _dom_classes=('widget-inter…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<function __main__.show_frame(i)>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def show_frame(i):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ret:\n",
        "        print('Failed to read frame', i)\n",
        "        return\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    t = i / fps\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.imshow(frame_rgb)\n",
        "    plt.title(f'frame={i}, time={t:.3f}s')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "slider = widgets.IntSlider(min=0, max=max_frames-1, step=1, value=0, description='frame')\n",
        "display(widgets.interact(show_frame, i=slider))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2617fc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b81c2da018434b26b01cec5436e0fac3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntText(value=260, description='LED frame'), Button(button_style='info', description='Play ±5 f…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76a03496f9644f4489f97519f28199ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, clear_output\n",
        "\n",
        "# LED_frame = 291 # swept sine\n",
        "# LED_frame = 415 # rampa positiva\n",
        "# LED_frame = 266 # rampa negativa\n",
        "# LED_frame = 273 # random_steps_W\n",
        "# LED_frame = 375 # random_steps_X\n",
        "# LED_frame = 238 # random_steps_Y\n",
        "# LED_frame = 288 # random_steps_Z\n",
        "# LED_frame = 279 # multisine_01\n",
        "LED_frame = 260 # multisine_02\n",
        "\n",
        "frame_input = widgets.IntText(value=LED_frame, description=\"LED frame\")\n",
        "play_button = widgets.Button(description=\"Play ±5 frames\", button_style=\"info\")\n",
        "out = widgets.Output()\n",
        "\n",
        "def show_frame(i):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ret:\n",
        "        print(\"Failed to read frame\", i)\n",
        "        return\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    t = i / fps\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.imshow(frame_rgb)\n",
        "    plt.title(f\"frame={i}, time={t:.3f}s\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def on_play(_):\n",
        "    with out:\n",
        "        clear_output(wait=True)\n",
        "        i0 = frame_input.value\n",
        "        for i in range(i0 - 5, i0 + 6):\n",
        "            if i < 0 or i >= frame_count:\n",
        "                continue\n",
        "            show_frame(i)\n",
        "\n",
        "play_button.on_click(on_play)\n",
        "display(widgets.HBox([frame_input, play_button]), out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
